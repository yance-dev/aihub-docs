## 快速开始

在登录后进入导航首页，点击跳转至AI Hub

![](images/模型训练/image-13.png)

支持创建普通训练任务或VIP任务，并支持查看和下载每个Pod的日志、k8s事件和yaml文件。

![](images/模型训练/image-14.png)


<div style="display: flex; justify-content: space-between;">
  <div style="text-align: center;">
    <img src="images/模型训练/image-10.png" alt="日志" style="width: 90%;"/>
    <p>日志</p>
  </div>
  <div style="text-align: center;">
    <img src="images/模型训练/image-11.png" alt="k8s事件" style="width: 90%;"/>
    <p>k8s事件</p>
  </div>
  <div style="text-align: center;">
    <img src="images/模型训练/image-12.png" alt="yaml文件" style="width: 90%;"/>
    <p>yaml文件</p>
  </div>
</div>


## 创建训练任务

![](images/模型训练/image.png)

![](images/模型训练/image-1.png)

**参数说明**

* 分类：任务的分类，根据实际情况从调试、推理、训练、特别中选择一个。

* 项目：任务所属的项目，可以从左侧菜单的 \[研发项目] 模块查看，若需添加请联系运维;

* 名称：训练任务的名称。

* 单机/多机：单机训练默认实例数量为1，不可更改，多机训练sku数量需大于等于5

* 框架

  * MpiJob，可以用mpirun或deepspeed的方式进行训练。系统会自动生成hostfile，路径在环境变量OMPI\_MCA\_orte\_default\_hostfile里面，可以在执行命令中使用该环境变量。注意：只有launcher节点才有hostfile，laucher节点就是Pod名称后面有laucher-xx的节点，ssh登录调试的时候要注意。

  * PyTorchJob，可以用pytorch的方式进行分布式训练。系统会自动生成MASTER\_ADDR, MASTER\_PORT, RANK, WORLD\_SIZE, PET\_NPROC\_PER\_NODE等环境变量，可以在执行命令中使用这些环境变量。PyTorchJob所有的环境变量如下：

    * MASTER\_PORT: master节点端口号

    * PET\_MASTER\_PORT: master节点端口号

    * MASTER\_ADDR: master节点地址&#x20;

    * PET\_MASTER\_ADDR: master节点地址

    * WORLD\_SIZE: GPU总数  &#x20;

    * RANK: 节点索引（取值0\~节点数-1）

    * PET\_NPROC\_PER\_NODE: 单节点的GPU数量

    * PET\_NODE\_RANK: 同RANK

    * PET\_NNODES: 节点总数

* 执行命令：MpiJob框架会在launcher节点执行命令，mpirun和deepspeed会自动SSH登录到worker节点执行训练命令。PyTorchJob框架和单机训练则会在所有节点执行命令，环境变量的值会自动根据节点生成。例如：

```bash
deepspeed示例命令：
deepspeed --hostfile $OMPI_MCA_orte_default_hostfile train.py

pytorch示例命令：
python -m torch.distributed.launch --nproc_per_node $PET_NPROC_PER_NODE --nnodes $PET_NNODES --node_rank $RANK --master_addr=$MASTER_ADDR --master_port=$MASTER_PORT train.py
```

一些NCCL和CUDA的环境变量如果设置错误，容易出现NCCL通信错误，相关说明和建议如下：

| 环境变量 | 用途 | 负面影响 | 建议值 |
|------|------|---------|---------|
| NCCL_DEBUG=INFO | 检查拓扑建立过程，是否成功调用IB/ROCE，获取底层异常信息等。 | （1）训练起来后仍会持续打印大量无价值的日志，掩盖有效信息；<br>（2）Pytorch分布式库本身对nccl异常包了一层，训练起来后nccl日志价值不大 | 非调试不应设置 |
| NCCL_SOCKET_IFNAME | 无论是单机多卡还是多机多卡，均需要一张**可正常TCP通信**的网卡进行初始化握手。如果有其他性能更好的网卡（IB/ROCE）可供使用，握手网卡不是最终要使用的网卡。 | 如果设置的网卡均不可用或不存在，nccl建立通信的流程报错 | 交给AI Hub平台自动设置。<br>开启IB网络时，自动设置为front1；<br>不开启IB网络时，自动设置为en。 |
| NCCL_IB_DISABLE=1 | 这个变量名有歧义，其实叫“**NCCL_RDMA_DISABLE**”更为合适。<br>用于强制RDMA网卡（IB网卡和ROCE网卡）按**普通以太网卡**使用，作为调试手段。| 经实测，可跑满100Gbps的ROCE网络，若被设置成普通以太网卡（**协议栈开销大、需要走CPU和PCIE绕远路**）使用，带宽仅可跑到**30Gbps**。 | 交给AI Hub平台自动设置。<br>开启IB网络时，自动设置为0；<br>不开启IB网络时，自动设置为1。<br><br>理论上ROCE也不应设置为1，ROCE不设置是否会导致训不起来还在调查中，欢迎提供案例。 |
| NCCL_P2P_DISABLE=1 | 强制关闭GPUtoGPU，GPUtoRDMA网卡的点对点通信。 | 本身支持点对点通信的GPU，被迫走CPU和PCIE绕远路，影响效率 | 正常情况下不应设置。<br>4090不支持P2P通信，早期某些机器因驱动和CUDA版本问题需要此设置避免报错。 |
| CUDA_LAUNCH_BLOCKING=1 | Pytorch中CPU做Kernel Launch和GPU做Kernel执行是异步操作，当GPU执行Kernel报错时，CPU已在执行后面的算子，给出的崩溃栈位置是不准确的。<br>使用该环境变量实现当前Kernel执行完成前，CPU堵塞，从而实现**CPU和GPU的强制同步**。 | 异步执行有利于缓解**CPU执行Python代码**  Launch Kernel跟不上GPU 执行Kernel效率的问题。强制同步会导致前向包含**大量的GPU等待CPU下发Kernel的时间（气泡时间）** | 非调试不应设置 |
| PYTORCH_NO_CUDA_MEMORY_CACHING=1 | 强制关闭Pytorch显存池<br>用于调试OOM问题。 | 显存临时分配和释放属于系统调用，开销较大<br>显存池将显存的分配和释放在用户态实现以减小开销<br>显然关闭显存池会有明显的性能开销 | 非调试不应设置 |


* 镜像地址：如果是MpiJob框架或者开启SSH，需要在镜像里面安装好SSH，Dockerfile的相关命令如下：

```bash
RUN apt-get update && apt-get install -y --no-install-recommends \
        openssh-client \
        openssh-server \
        pdsh \
        && rm -rf /var/lib/apt/lists/*
```

另外，不要修改ssh的默认端口号（22），也就是/etc/ssh/ssh\_config里面的Port，否则会导致worker节点训练无法启动。

* 总是拉取镜像：如果选是，则启动任务的时候会拉取最新的镜像；如果选择否，则会用已有的镜像。

* 虚拟集群：按GPU资源分组的虚拟集群。集群可用的资源可以在左侧菜单的【资源面板】查看。

  目前有两个虚拟集群

  * A800-960G-120core: 2台

  * 4090-960G-88core: 10台

* SKU数量：每个节点分配的资源数量。单个节点消耗的资源数等于：SKU数量\*虚拟集群SKU资源。

* 共享内存：单位GB，建议。

* 实例数量：训练节点（Node）的数量，worker节点数量。

* 开启SSH：如果开启SSH，需要先在镜像中安装好SSH。之后在POD详情中的SSH信息中可以看到登录SSH的方法，例如：

```bash
请用以下命令登录到POD中(默认登录密码是“root”): ssh -p 2345 root@192.168.13.160
```

* IB网络：如果开启IB网络，需要虚拟集群支持才行。

* 预估运行时长：训练任务运行完成需要的大致时长，支持精确到秒。

* 描述：选填。

* 环境变量：配置环境变量后，会打到每个pod中

* 数据存储：可访问的外部存储，勾选后可在pod内访问，路径字段为在pod内访问的路径，目前支持的存储

  * LC-data 浪潮存储

  * HW-data 华为全闪存储



## 创建VIP任务

点击创建VIP任务的按钮，跳转至创建页

![](images/模型训练/image-2.png)



所有参数设置都和创建普通的训练任务一样，只是需要在右侧的`VIP任务资源调度`模块勾选机器以保证VIP任务的第一时间运行。可以选择等待勾选机器上的任务完成，也可以选择立即杀死勾选机器上的任务。

![](images/模型训练/image-3.png)

在选择虚拟集群后，可以在`VIP任务资源调度`模块看到该虚拟集群的机器列表。优先展示没有被任务占用的机器，有任务占用的机器可以看到该机器上正在运行的任务列表。根据任务的运行情况选择需要抢占的机器，**若需要立即杀死任务建议先和任务的创建人协商好**。在普通任务因VIP任务被杀死后，可以在详情页看到杀死任务的操作人。若事先未协商发现自己的任务被杀死，可以找相应的操作人沟通。

![](images/模型训练/image-4.png)

创建后可以看到训练任务有VIP的标识，VIP任务不会被其他任务杀死，同样支持停止和复制。

![](images/模型训练/image-5.png)



## 查看资源指标

1. 查看任务的资源指标

点击任务名称跳转到详情页

![](images/模型训练/image-6.png)

点击资源指标按钮跳转到监控页

![](images/模型训练/image-7.png)

查看该任务当前的资源指标

![](images/模型训练/image-8.png)



2. 查看Pod的资源指标

点击Pod名称跳转到详情页

![](images/模型训练/image-9.png)

点击资源指标按钮跳转到监控页

![](images/模型训练/image-15.png)

查看该Pod当前的资源指标

![](images/模型训练/image-16.png)





## 环境变量检查

在导致训练任务失败的原因中，大多数问题是环境变量设置有误引起的。例如引用的环境变量没有初始化导致工作节点Fail、开启IB网络但没有设置相关的环境变量导致socket timeout等等。因此环境变量检查工具能够协助用户更快地定位并解决问题，用户通过埋点的方式上报环境变量后，检查工具会将分析结果通知到用户。如下所示：

![](images/模型训练/image-17.png)



使用环境变量检查工具的步骤如下：

1. 创建训练任务时，在执行训练脚本之前，安装埋点sdk。安装命令如下：

```bash
python3 -m pip install --trusted-host 192.168.99.216 -i http://192.168.99.216:8081/repository/python/simple git+http://pip_ak:wv8GUNr19k7AHHckLdqZ@192.168.99.198/aisdp/data_service/aitc_tools.git
```

例如：

![](images/模型训练/image-18.png)

2. 编辑训练脚本，在训练执行前添加:

```python
from aitc_tools import mtp_reporter;mtp_reporter.report_envs()
```

例如：

```python
...
from aitc_tools import mtp_reporter;mtp_reporter.report_envs()

torch.distributed.init_process_group()
...
```




